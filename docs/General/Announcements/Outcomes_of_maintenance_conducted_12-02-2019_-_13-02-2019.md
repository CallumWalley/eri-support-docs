[From 9am 12/02/2019 to 10am 13/02/2019 NeSI performed maintenance
during a planned outage to multiple components of both Mahuika and
]{style="font-weight: 400;"}[Māui]{style="font-weight: 400;"}[,
including their shared storage. The following is a brief list of the
activities performed during this outage and some of the improvements to
service as a result:]{style="font-weight: 400;"}

-   [At the beginning and end of the outage window, we conducted
    performance degradation testing, using a suite of microbenchmarks
    and real science codes, to check for unexplained performance
    variations.]{style="font-weight: 400;"}
-   [Vendor-recommended updates were made to critical systems firmware
    and BIOS.]{style="font-weight: 400;"}
-   [Operating system upgrades were made to critical
    servers.]{style="font-weight: 400;"}
-   [Upgrades to our HPC filesystems (Spectrum Scale) provided fixes for
    several ongoing issues, including client system deadlocks that were
    triggered by particular application
    workloads.]{style="font-weight: 400;"}
-   [More memory is now available for user applications, as a result of
    HPC filesystem (Spectrum Scale) tuning down of reserved systems
    resources on compute nodes]{style="font-weight: 400;"}
-   [[Mahuika login node
    environment]{style="font-weight: 400;"}](https://support.nesi.org.nz/hc/en-gb/sections/360000040056-HPC-Software-Environment)[
    now automatically loads the top-level NeSI Module into user's shell
    environment.]{style="font-weight: 400;"}
-   [Slurm job profiling plugin has been enabled on Mahuika. Generic
    documentation can be found on the
    ]{style="font-weight: 400;"}[[Slurm
    website]{style="font-weight: 400;"}](https://slurm.schedmd.com/hdf5_profile_user_guide.html)[,
    NeSI specific documentation is being drafted but not yet
    published.]{style="font-weight: 400;"}

[We appreciate your patience and understanding during these activities.
As always, if you have any related questions, please don't hesitate to
contact ]{style="font-weight: 400;"}[[NeSI
Support]{style="font-weight: 400;"}](https://support.nesi.org.nz/hc/en-gb/articles/360000748496-User-support)[.]{style="font-weight: 400;"}

***Additional Background***[\
]{style="font-weight: 400;"}[NeSI regularly performs scheduled
maintenance on various components of its high performance computers
(HPCs) to ensure robust and performant operations. Whenever possible,
such works are carried out during regular operations in order to
minimise user impact, however some more intrusive maintenance activities
simply cannot be done without taking critical shared services offline
(e.g., high performance filesystems) or must be done consistently across
all systems as quickly as possible. Therefore, we must have occasional
planned outages were no user activity is possible on the
HPCs.]{style="font-weight: 400;"}

[Whenever scheduled maintenance is required, particularly if it requires
critical shared services to be taken offline, we will notify users in
advance by email and post a status update to
]{style="font-weight: 400;"}[[status.nesi.org.nz]{style="font-weight: 400;"}[.]{style="font-weight: 400;"}](https://status.nesi.org.nz/)[ From
that status page, u]{style="font-weight: 400;"}[sers can subscribe to
receive system-specific or all status
updates]{style="font-weight: 400;"}[. ]{style="font-weight: 400;"}

[If you have questions about these maintenance and outage processes,
please contact ]{style="font-weight: 400;"}[[NeSI
Support]{style="font-weight: 400;"}](mailto:support@nesi.org.nz)[.]{style="font-weight: 400;"}
